#!.venv/bin/python

# expects to run from repo root

import json
import subprocess
import _jsonnet  # type: ignore
import requests
import re

from datetime import date

# Typing imports
from typing import TypeAlias

IMAGES_JSONNET_PATH = 'tanka/lib/images.libsonnet'

HOTIO_RELEASE_REGEX = r'release-(?:\d+\.)+\d+'
TAG_REGEX = {
    'prowlarr': HOTIO_RELEASE_REGEX,
    'sonarr': HOTIO_RELEASE_REGEX,
    'radarr': HOTIO_RELEASE_REGEX,
    'qbittorrent': HOTIO_RELEASE_REGEX,
    'promtail': r'\d+\.\d+\.\d+',
    'tautulli': r'v\d+\.\d+\.\d+',
}

ImageDef: TypeAlias = dict[str, str]
TagData: TypeAlias = dict[str, str]
# The TagData TypeAlias is not strictly correct; there can be ints, but I'm not currently using them.
# Will expand this out if needed later


def main():
    check_for_image_updates()


# Runs through the images lib and checks for updates for each image
# "followTag" is a tag that *should* follow a versioned release. Poll the tags of the image to find the version tag
# that matches its digest and use that.
# Once done, format the results back through jsonnetfmt and write to the lib file
# If any of the images match multiple tags, the script aborts without writing anything
def check_for_image_updates():
    images: dict[str, ImageDef] = json.loads(_jsonnet.evaluate_file(IMAGES_JSONNET_PATH))['images']
    will_update_file = True
    for app, detail in images.items():
        if date.fromisoformat(detail.get('lastChecked', "1970-01-01")) == date.today():
            continue
        image = detail['image']
        tag = detail['followTag']
        image_updates = get_image_update(app, image, tag)
        # Check if we found a unique image to use
        if len(image_updates) == 1:
            # Special case for Pihole, since it currently pre-pulls with a DaemonSet
            if app == 'pihole':
                images[app]['prepullImage'] = image_updates[0]
            else:
                images[app]['image'] = image_updates[0]
        else:
            print(f"Multiple tags found: {image} -> {image_updates}")
            will_update_file = False
        images[app]['lastChecked'] = str(date.today())

    if will_update_file:
        output = jsonnetfmt_dumps({'images': images})
        with open(IMAGES_JSONNET_PATH, "w") as f:
            f.write(output)
    else:
        print("Some images had multiple possible tags. Not updating images lib.")
        exit(1)


# Check for update to a single image
def get_image_update(app: str, current_image: str, tag_to_check: str) -> list[str]:
    image_id, current_tag = current_image.rsplit(":", 1)
    image_tag_template = image_id + ":{}"
    owner, image_name = image_id.rsplit("/", 1)

    tags: dict[str, TagData] = {}

    # Query image repo in pages until we find the tag we want
    # Possible edge-case: tag we want is updated after another versioned tag, and that versioned tag is on
    # the next page. If I ever notice that happen, I'll add another page query here.
    page_size = 20  # Most images don't have a lot of tags
    page_num = 1
    page_max = 5  # ...but sometimes they publish a new tag for every fucking commit

    while tag_to_check not in tags.keys() and page_num <= page_max:
        tags_url = f'https://hub.docker.com/v2/namespaces/{owner}/repositories/{image_name}/tags' + \
                    f'?page_size={page_size}' + \
                    f'&page={page_num}'
        response = requests.get(tags_url)
        tags_list: list[TagData] = json.loads(response.text)['results']
        # Add the list into a dict keyed on the tag's name for ease of use later
        for tag_data in tags_list:
            if 'digest' in tag_data.keys():
                # idk if a missing digest means a tag is deprecated or something, but it can occur. Skip those.
                tags[tag_data['name']] = tag_data
        page_num += 1
    # Verify we got the tag
    if tag_to_check not in tags.keys():
        raise Exception(f"scanned so many fucking tags and still couldn't find tag '{tag_to_check}' for '{image_id}")

    # Loop through the tags and find ones with digests matching the tag we want
    # The regex match is used to filter out duplicates for some images
    check_digest = tags[tag_to_check]['digest']
    potential_images = []
    for tag, data in tags.items():
        if data['digest'] == check_digest and \
           tag != tag_to_check and \
           tag != 'latest' and \
           re.match(TAG_REGEX.get(app, '.*'), tag):
            potential_images.append(image_tag_template.format(tag))

    # Did that work?
    if not len(potential_images):
        # If here, this app sucks and doesn't have a tag that follows versioned releases.
        # Resort to checking all tags that match the regex to see if any are newer than the current tag
        newest_tag_date = tags[current_tag]['tag_last_pushed']
        newest_tag = current_tag
        for tag, data in tags.items():
            if re.match(TAG_REGEX.get(app, '.*'), tag) and 'tag_last_pushed' in data.keys():
                date = data['tag_last_pushed']
                if date > newest_tag_date:
                    newest_tag_date = date
                    newest_tag = tag
        potential_images.append(image_tag_template.format(newest_tag))
    return potential_images


# Wrapper for running the output of json.dumps through jsonnetfmt
def jsonnetfmt_dumps(input: dict) -> str:
    json_str = json.dumps(input, indent=2, sort_keys=True)
    return subprocess.run(["jsonnetfmt", "-"], input=json_str, text=True, capture_output=True).stdout


if __name__ == "__main__":
    main()
